# Serving Playbook

This directory now has two independent runtimes:

1. `serve-llm/` — vLLM-based hosting for the LoRA/QLoRA adapter (OpenAI-compatible).
2. `serve-transformer/` — FastAPI runtime for the structured multi-head transformer.

Follow the README inside each subfolder for setup and runtime instructions.
