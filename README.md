# ğŸ§  AMLâ€“LLM Hybrid Simulator
Train a Small Llama Model to Emulate a Retail Banking Antiâ€“Moneyâ€“Laundering (AML) Rule Engine  

---

## ğŸ“˜ Overview
This project demonstrates how to **convert a symbolic rule engine (Drools)** into a **trainable dataset** for a **small language model (LLM)**.  
We simulate retail banking antiâ€“moneyâ€“laundering decisions â€” `CLEAR`, `REVIEW`, `SAR`, `BLOCK` â€” based on structured transaction data.  
Then we fine-tune a **Llama-3 3B** model with **QLoRA adapters** to imitate those rules in natural-language inference form.

---

## ğŸ§© Architecture
```text
Drools Rules (.drl)
   â†“
Java Runner (fires rules â†’ JSON output)
   â†“
Python Generator (produces 100k+ labeled cases)
   â†“
QLoRA Fine-tuning (3B Llama model on 1Ã— H100)
   â†“
LLM â€œRule Engineâ€ (predicts AML decision + escalation)
```

---

## ğŸ“‚ Directory Layout
```
aml-llm/
â”œâ”€â”€ rules/
â”‚   â””â”€â”€ tx_aml.drl
â”œâ”€â”€ drools-runner/
â”‚   â”œâ”€â”€ pom.xml
â”‚   â””â”€â”€ src/main/java/demo/Runner.java
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ make_tx_aml_dataset.py
â”‚   â”œâ”€â”€ split_dataset.py
â”‚   â””â”€â”€ tx_aml_dataset.jsonl
â””â”€â”€ training/
    â”œâ”€â”€ requirements.txt
    â”œâ”€â”€ map_facts_to_text.py
    â””â”€â”€ train_qlora.py
```

---

## âš™ï¸ Prerequisites
- Java 17+
- Maven 3.9+
- Python 3.10+
- NVIDIA H100/A100/RTX3090+ (CUDA 12)
- Hugging Face access to [`meta-llama/Llama-3.2-3B-Instruct`](https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct)

---

## ğŸ—ï¸ 1. Build the Drools Runner
```bash
cd drools-runner
mvn -q -DskipTests package
# â†’ target/drools-runner-1.0.0-shaded.jar
```

Test once:
```bash
java -jar target/drools-runner-1.0.0-shaded.jar ../rules/tx_aml.drl ../data/sample.json
```

---

## ğŸ§® 2. Generate Dataset
```bash
cd data
python make_tx_aml_dataset.py 50000 tx_aml_dataset.jsonl
python split_dataset.py tx_aml_dataset.jsonl
```
Expected sizes: 80 % train | 10 % val | 10 % test.

---

## ğŸ§  3. Fine-Tune the Model (QLoRA)
```bash
cd training
pip install -r requirements.txt
export MODEL_ID="meta-llama/Llama-3.2-3B-Instruct"
accelerate launch train_qlora.py
```

This trains a 4-bit QLoRA adapter (~200 MB) on your dataset using 1Ã— H100.

---

## ğŸ“Š 4. Evaluate
Metrics:
- Decision accuracy (CLEAR / REVIEW / SAR / BLOCK)
- Escalation-level exact match
- Reasons F1 (multilabel)
- Rule-coverage completeness  
Use the Drools engine as the ground truth.

---

## ğŸ¤– 5. Inference Prompt Example
```
You are an AML rule engine simulator.
Given the facts (JSON), output ONLY this JSON:
{"aml_decision":"CLEAR|REVIEW|SAR|BLOCK","reasons":[...],"escalation_level":0-3}

Facts:
{...}
```
Expected LLM response:
```json
{"aml_decision":"REVIEW","reasons":["LARGE_WIRE","ODD_HOUR"],"escalation_level":2}
```

---

## ğŸ“ˆ Recommended Training Scale
| Dataset Size | Expected Accuracy | GPU Time (1Ã— H100, 2 epochs) |
|--------------:|-----------------:|------------------------------:|
| 20 k  | 85â€“90 % | ~1 h |
| 100 k | 95 % + | ~4 h |
| 250 k | 97 % + | ~8 h |

Tip: aim for balanced coverage of every rule and edge case rather than sheer volume.

---

## ğŸ§ª LoRA vs QLoRA
| Method | VRAM | Speed | Accuracy (typical) | When to use |
|--------|------|--------|--------------------|-------------|
| **QLoRA** | ğŸŸ¢ Low (4-bit) | âš¡ Fast | â‰ˆ LoRA | Default |
| **LoRA**  | ğŸŸ  Higher (bf16) | Moderate | +0â€“1 % | Max fidelity |
| **Full SFT** | ğŸ”´ High | Slow | +0â€“1 % | Research-only |

---

## ğŸ§± Next Steps
- Expand DRL rules with your own AML thresholds.  
- Add **hard-example mining** (misclassified cases).  
- Test zero-shot transfer to unseen rule combos.  
- Integrate with Drools validator for hybrid guardrails.

---

## âš–ï¸ License
MIT License.  
Ruleset is illustrative and **not** a production AML policy.

---

## ğŸ‘¨â€ğŸ’» Author & Credits
Built with assistance from **ChatGPT (GPT-5)** and **Red Hat OpenShift AI** best practices.  
Use freely for research, prototyping, or internal model-evaluation projects.
# Rule-Generator-AML
